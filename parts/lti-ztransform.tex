% vim:ts=2 sw=2 noet spell tw=78:

\section{Signals}

Given two signals $f$ and $g$ the \emph{superposition} principle states that
$(f+g)(t) = f(t) + g(t)$, while the amplification by $\gamma$ is $(\gamma
f)(t) = \gamma f(t)$. Now, given a discrete signal $f[k]$, the \emph{reverse}
of $f$ denoted by $f^r[k] = f[-k]$. If $f$ is complex, the \emph{conjugate} of
$f$ is $f^c[k] = \overline{f[-k]}$.

\subsection{Classes}

A complex ($\mathbb{K}=\mathbb{C}$) or real ($\mathbb{K}=\mathbb{R}$),
discrete or continuous signal $f$ is said to be \emph{stable} or absolutely
summable (integrable) iff
\begin{align*}
	\sum_{k \in \mathbb{Z}} |f[k]| < \infty
		& \qquad (f\in\ell^1_\mathbb{K}(\mathbb{Z})) \quad\text{or} \\
	\int_\mathbb{R} |f(t)| \,dt < \infty 
		& \qquad (f \in L^1_\mathbb{K}(\mathbb{R}))
\end{align*}
respectively. Similarly, a signal has \emph{finite energy} or is square
summable (integrable) iff
\begin{align*}
	\sum_{k\in\mathbb{Z}} |f[k]|^2
	&= \sum_{k\in\mathbb{Z}} f[k] \overline{f[k]} < \infty
		&& (f\in\ell^2_\mathbb{K}(\mathbb{Z})), \\
	\int_\mathbb{R} |f(t)|^2 \,dt 
	&= \int_\mathbb{R} f(t) \overline{f(t)} \, dt < \infty 
		&& (f \in L^2_\mathbb{K}(\mathbb{R})).
\end{align*}
Further, a signal is said to be \emph{bounded} if $\exists b < \infty$ such
that
\[
	\forall k \in \mathbb{Z} : |f[k]| < b,
	\quad\text{or}\quad
	\forall t \in \mathbb{R} : |f(t)| < b.
\]
The set of bounded discrete and continuous signals are denoted with
$\ell^\infty_\mathbb{K}(\mathbb{Z})$ and $L^\infty_\mathbb{K}(\mathbb{R})$
respectively. Note that
\[
	\ell^1_\mathbb{K}(\mathbb{Z}) \subset
	\ell^2_\mathbb{K}(\mathbb{Z}) \subset
	\ell^\infty_\mathbb{K}(\mathbb{Z}).
\]
Finally, a signal is said to be \emph{right sided} if
\[
	\exists \tau \in \mathbb{R} : \forall t < \tau : f(t) = 0,
\]
and similarly \emph{left sided} if 
\[
	\exists \tau \in \mathbb{R} : \forall t > \tau : f(t) = 0.
\]
Signals that are right sided for some $\tau > 0$ are said to be \emph{causal},
while left sided signals for $\tau < 0$ are said to be \emph{anticausal}. The
same definition also applies for a discrete signal $f[k]$, for example
$\exists n \in \mathbb{Z} : \forall k > n : f[k] = 0$.

\subsection{Dirac and Kroneker delta}

The Kroneker delta is like the identity matrix but as discrete function
\[
	\delta[k] = \begin{cases}
		1 & \text{if } k = 0, \\
		0 & \text{otherwise}.
	\end{cases}
\]
The Dirac delta is a distribution, which
is the limit of a sequence of functions $\lim_{n \to \infty} \delta_n(t)$,
where $\delta_n(t < 1/(2n)) = n$ otherwise $\delta(t) = 0$. The important
property of $\delta(t)$ is that
\[
	\int_\mathbb{R} f(t) \delta(t - \tau) \, dt = f(\tau).
\]

\section{The $z$-Transform}

\subsection{Formal Definition and Properties}

For a discrete signal $f[k]$ its \emph{formal} $z$-transform $F(z) $ is
defined to be
\[
	F(z) = \mathcal{Z}\{f\} = \sum_{k\in\mathbb{Z}} f[k] z^{-k}.
\]
The $z$-transforms $F(z)$ and $G(z)$ of $f[k]$ and $g[k]$ respectively have
the following properties:
\begin{description}
	\item[Addition] $F(z) + G(z) = \mathcal{Z}\{(f + g)[\cdot]\}$,
	\item[Scaling] For $a \in \mathbb{C} : a F(z) = \mathcal{Z}\{(af)[\cdot]\}$,
	\item[Time shift] For $m \in \mathbb{Z} :
		z^m F(z) = \mathcal{Z}\{f[\cdot + m]\}$,
	\item[Product] $F(z) G(z) = \mathcal{Z}\{(f * g)[\cdot]\}$.
\end{description}
The time shift is to the left (past) if $m > 0$ and to the right (future) when
$m < 0$. The product is defined only if $f*g$ is well defined in the time
domain, further, sometimes but not always (!)
\[
	F(z)[G(z)H(z)] = [F(z)G(z)]H(z).
\] A few more properties are
\begin{description}
	\item[Time reversal] $F(z^{-1}) = \mathcal{Z}\{f^r[\cdot]\}$,
	\item[Conjugation] $\mathcal{Z}\{f^c[\cdot]\}
		= \mathcal{Z}\{\overline{f^r[\cdot]}\}
		= \overline{F(\overline{z}^{-1})}$.
\end{description}
It might also be useful to know that
\[
	\mathcal{Z}\{\Re{(f[\cdot])}\}
	= \mathcal{Z}\left\{\frac{f[\cdot] + \overline{f[\cdot]}}{2}\right\}
	= \frac{F(z) + \overline{F(\overline{z})}}{2}
\]
and similarly one can use that $\Im(f[\cdot]) = (f[\cdot] -
\overline{f[\cdot]})/2i$. Finally, the following notation is to indicate the
causal part of $F(z)$:
\[
	F(z) \mod z = \sum_{k=0}^\infty f[k] z^{-k}.
\]

\subsection{Analytic Definition and the Region of Convergence (ROC)}

If we treat the $z$-transform as a function of the complex number $z$ we have
to be more careful and define a ROC. We call this the \emph{analytical}
$z$-transform and write
\[
	F : \roc(f) \to \mathbb{C}, \quad
	z \mapsto \sum_{k\in\mathbb{Z}} f[k]z^{-k},
\]
where
\begin{align*}
	\roc(f) &= \{z \in \mathbb{C} : r_1 < |z| < r_2\}, \\
	r_1 &= \limsup_{k\to\infty} \sqrt[k]{|f[k]|}, \\ 
	r_2 &= \limsup_{k\to\infty} \left(\sqrt[k]{|f[-k]|}\right)^{-1}.
\end{align*}
The ROC follows has the following algebraic properties. Let $f,g,h$ be
discrete signals:
\begin{description}
	\item[Addition] $\roc(f) \cap \roc(g) \subseteq \roc(f + g)$,
	\item[Scaling] For $a \in \mathbb{C} \setminus \{0\} : \roc(af) = \roc(f)$,
	\item[Time shift] If we let $H(z) = z^m F(z)$ with $m \in \mathbb{Z}$ then
		$\roc(h) = \roc(f)$,
	\item[Product] $\roc(f) \cap \roc(g) \subseteq \roc(f * g)$,
	\item[Time reversal] If $r_1$ and $r_2$ are the radii of the ROC of $f$,
		then $\roc(f^r) = \{ z \in\mathbb{C} : 1/r_2 < |z| < 1/r_1 \}$.
\end{description}
If the unit circle is contained in $\roc(f)$ then $f[\cdot]$ is stable, i.e.
$r_1 \leq 1$ and $r_2 \geq 1$, moreover if $F(z)$ is rational the converse is
also true.

\section{Systems}

A system or model is made of two parts: a set of variables that take some
value in a \emph{configuration space} and a \emph{permitted behaviour}, which
is a subset of the configuration space. A system is said to be
\emph{dynamical} if some or all variables are functions of time. Further a
system is said to be \emph{linear} is the configuration space is a
\emph{vector space}, and the permitted behaviour is a \emph{subspace} of the
configuration space. Connecting two linear systems yields a linear system.

Finally, systems can be classified as being \emph{single-input single-output}
(SISO), \emph{multiple-input multiple-output} (MIMO) or a combination of the
two. SISO systems whose output signal $y$ is fully determined by the
input $u$ are said to be \emph{deterministic}, and if $y(t)$ is fully determined
by $u(t')$ when $t' \leq t$, the system is said to be \emph{causal}.

\subsection{Linear Time Invariant (LTI) Systems}

An LTI is entirely described by its \emph{impulse response} $h$. The output
$y$ to an arbitrary input $u$ is given by convolving it with the impulse
response:
\begin{align*}
	y[k] &= (u * h)[k] = \sum_{n\in\mathbb{Z}} u[n] h[k - n], \\
	y(t) &= (u * h)(t) = \int_\mathbb{R} u(\tau) h(t - \tau) \, dt.
\end{align*}
A system is causal iff $h$ is causal, i.e. $h[k < 0] = 0$, $h(t < 0) = 0$. A
SISO system is \emph{bounded-input bounded-output} (BIBO) stable if $h$ is
stable.

\begin{table}
	\centering
	\begin{tabular}{ccc}
		\toprule
		$f$ & $g$ & $f * g$ \\
		\midrule
		right-sided & right-sided & right-sided  \\
		causal      & causal      & causal       \\
		anything    & finite      & well defined \\
		\midrule
		\bfseries bounded
			& $\ell^1\text{ or }L^1$
			& \bfseries bounded \\
		$\ell^1\text{ or }L^1$
			& $\ell^1\text{ or }L^1$
			& $\ell^1\text{ or }L^1$ \\
		\midrule
		$\ell^2\text{ or }L^2$
			& $\ell^1\text{ or }L^1$
			& $\ell^2\text{ or }L^2$ \\
		$\ell^2\text{ or }L^2$
			& $\ell^2\text{ or }L^2$
			& bounded \\
		\bottomrule
	\end{tabular}
	\caption{
		Important properties of the convolution product. Further note that $f * g
		= g * f$, and that bounded means $\in \ell^\infty$ or $\in L^\infty$.
	}
\end{table}
